{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0+cu116\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "conv = nn.Conv2d(1,3,3,2)\n",
    "data = torch.randn([2,1,5,5])\n",
    "print(conv(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.ModelFaceNet_base import MobileFaceNet, Layer_congif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mbf(num_features = 128):\n",
    "    expand_size = 2\n",
    "    net_para = [\n",
    "        Layer_congif(3, 16, 16, 1, 2),\n",
    "        Layer_congif(16, 32, 64, 1, 1),\n",
    "        Layer_congif(64, 128, 128, 1, 1),\n",
    "        \n",
    "        Layer_congif(64, 128, 128, 1, 2),\n",
    "        Layer_congif(128, 256, 128, 4, 1),\n",
    "        \n",
    "        Layer_congif(128, 256, 256, 1, 2),\n",
    "        Layer_congif(256, 256, 256, 6, 1),\n",
    "        \n",
    "        Layer_congif(256, 512, 256, 1, 2),\n",
    "        Layer_congif(256, 512, 256, 2, 1)\n",
    "    ]\n",
    "    return MobileFaceNet(net_para = net_para, \n",
    "                         num_features = num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MobileFaceNet' object has no attribute 'ch_set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mget_mbf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m112\u001b[39m,\u001b[38;5;241m112\u001b[39m])\n",
      "Cell \u001b[1;32mIn[26], line 17\u001b[0m, in \u001b[0;36mget_mbf\u001b[1;34m(num_features)\u001b[0m\n\u001b[0;32m      2\u001b[0m expand_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      3\u001b[0m net_para \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      4\u001b[0m     Layer_congif(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m      5\u001b[0m     Layer_congif(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     Layer_congif(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     16\u001b[0m ]\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMobileFaceNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_para\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnet_para\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Desktop\\palm_vein\\test_file\\..\\model\\ModelFaceNet_base.py:31\u001b[0m, in \u001b[0;36mMobileFaceNet.__init__\u001b[1;34m(self, fp16, net_para, num_features)\u001b[0m\n\u001b[0;32m     26\u001b[0m     first_l\u001b[38;5;241m.\u001b[39min_ch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m# [bs, 3, m,n] -> [bs, 64*s, m/2,n/2]\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     Conv_bn_act(first_l\u001b[38;5;241m.\u001b[39min_ch, first_l\u001b[38;5;241m.\u001b[39mout_ch, kernel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), stride\u001b[38;5;241m=\u001b[39mfirst_l\u001b[38;5;241m.\u001b[39mstride, padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mch_set\u001b[49m:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m layer_ch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;66;03m# 只有一层\u001b[39;00m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m     35\u001b[0m             DepthWise(layer_ch\u001b[38;5;241m.\u001b[39min_ch, layer_ch\u001b[38;5;241m.\u001b[39mout_ch, groups \u001b[38;5;241m=\u001b[39m layer_ch\u001b[38;5;241m.\u001b[39mex_ch, \n\u001b[0;32m     36\u001b[0m                       kernel\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), stride\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), padding\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     37\u001b[0m         )\n",
      "File \u001b[1;32md:\\Anaconda3\\envs\\palm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1265\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1265\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MobileFaceNet' object has no attribute 'ch_set'"
     ]
    }
   ],
   "source": [
    "from typing import Callable, List, Optional\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn import functional as F\n",
    "from functools import partial\n",
    "\n",
    "# 得到同传入数据最近的8的整数倍数值\n",
    "def _make_divisible(ch, divisor=8, min_ch=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_ch is None:\n",
    "        min_ch = divisor\n",
    "    new_ch = max(min_ch, int(ch + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_ch < 0.9 * ch:\n",
    "        new_ch += divisor\n",
    "    return new_ch\n",
    "\n",
    "# 普通卷积、BN、激活层模块\n",
    "class ConvBNActivation(nn.Sequential):\n",
    "    def __init__(self,\n",
    "                 in_planes: int,   # 输入特征矩阵的通道\n",
    "                 out_planes: int,  # 输出特征矩阵的通道\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 groups: int = 1,\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None,   # 在卷积后的BN层\n",
    "                 activation_layer: Optional[Callable[..., nn.Module]] = None):  # 激活函数\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if activation_layer is None:\n",
    "            activation_layer = nn.ReLU6\n",
    "        super(ConvBNActivation, self).__init__(nn.Conv2d(in_channels=in_planes,\n",
    "                                                         out_channels=out_planes,\n",
    "                                                         kernel_size=kernel_size,\n",
    "                                                         stride=stride,\n",
    "                                                         padding=padding,\n",
    "                                                         groups=groups,\n",
    "                                                         bias=False),\n",
    "                                               norm_layer(out_planes),   # BN层\n",
    "                                               activation_layer(inplace=True))\n",
    "\n",
    "# 注意力机制模块（SE模块，即两个全连接层）   该模块的基本流程是：先进行自适应平均池化(1x1)———>1x1的卷积层———>relu激活层———>1x1的卷积池化———>hardsigmoid()激活函数激活\n",
    "class SqueezeExcitation(nn.Module):\n",
    "    def __init__(self, input_c: int, squeeze_factor: int = 4):\n",
    "        super(SqueezeExcitation, self).__init__()\n",
    "        squeeze_c = _make_divisible(input_c // squeeze_factor, 8)    # 获得距离该数最近的8的整数倍的数字\n",
    "        self.fc1 = nn.Conv2d(input_c, squeeze_c, 1)    # 该卷积的输出的squeeze_c是输入input_c的1/4  其作用与全连接层一样\n",
    "        self.fc2 = nn.Conv2d(squeeze_c, input_c, 1)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        scale = F.adaptive_avg_pool2d(x, output_size=(1, 1))   # 将特征矩阵每一个channel上的数据给平均池化到1x1的大小\n",
    "        scale = self.fc1(scale)\n",
    "        scale = F.relu(scale, inplace=True)\n",
    "        scale = self.fc2(scale)\n",
    "        scale = F.hardsigmoid(scale, inplace=True)   # 激活函数\n",
    "        return scale * x   # 将得到的数据与传入的对应channel数据进行相乘\n",
    "\n",
    "\n",
    "# 定义block的配置类\n",
    "class InvertedResidualConfig:\n",
    "    def __init__(self,\n",
    "                 input_c: int,  # block模块中的第一个1x1卷积层的输入channel数\n",
    "                 kernel: int,   # depthwise卷积的卷积核大小\n",
    "                 expanded_c: int,   # block模块中的第一个1x1卷积层的输出channel数\n",
    "                 out_c: int,  # 经过block模块中第二个1x1卷积层处理过后得到的channel数\n",
    "                 use_se: bool,  # 是否使用注意力机制模块\n",
    "                 activation: str,   # 激活方式\n",
    "                 stride: int,       # 步长\n",
    "                 width_multi: float):  # width_multi：调节每个卷积层所使用channel的倍率因子\n",
    "        self.input_c = self.adjust_channels(input_c, width_multi)\n",
    "        self.kernel = kernel\n",
    "        self.expanded_c = self.adjust_channels(expanded_c, width_multi)\n",
    "        self.out_c = self.adjust_channels(out_c, width_multi)\n",
    "        self.use_se = use_se\n",
    "        self.use_hs = activation == \"HS\"  # whether using h-swish activation\n",
    "        self.stride = stride\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_channels(channels: int, width_multi: float):\n",
    "        return _make_divisible(channels * width_multi, 8)\n",
    "\n",
    "\n",
    "\n",
    "# 定义block模块\n",
    "# 此为block模块，其包含第一个1x1卷积层、DeptWis卷积层、SE注意力机制层（判断是否需求）、第二个1x1卷积层、激活函数（需要判断是否是非线性激活）\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self,\n",
    "                 cnf: InvertedResidualConfig,   # cnf:配置类参数\n",
    "                 norm_layer: Callable[..., nn.Module]):      # norm_layer：# BN层\n",
    "        super(InvertedResidual, self).__init__()\n",
    "\n",
    "        if cnf.stride not in [1, 2]:  # 判断某一层的配置文件，其步长是否满足条件\n",
    "            raise ValueError(\"illegal stride value.\")\n",
    "\n",
    "        # 判断是否进行短连接\n",
    "        self.use_res_connect = (cnf.stride == 1 and cnf.input_c == cnf.out_c)  # 只有当步长为1，并且输入通道等于输出通道数\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.Hardswish if cnf.use_hs else nn.ReLU    # 判断当前的激活函数类型\n",
    "\n",
    "        # expand\n",
    "        # 判断是否相等，如果相等，则不适用1x1的卷积层增加channel维度；不相等的话，才使用该层进行升维度\n",
    "        if cnf.expanded_c != cnf.input_c:\n",
    "            layers.append(ConvBNActivation(cnf.input_c,\n",
    "                                           cnf.expanded_c,\n",
    "                                           kernel_size=1,\n",
    "                                           norm_layer=norm_layer,\n",
    "                                           activation_layer=activation_layer))\n",
    "\n",
    "        # depthwise\n",
    "        layers.append(ConvBNActivation(cnf.expanded_c,\n",
    "                                       cnf.expanded_c,\n",
    "                                       kernel_size=cnf.kernel,   # depthwise卷积的卷积核大小\n",
    "                                       stride=cnf.stride,\n",
    "                                       groups=cnf.expanded_c,    # 深度DW卷积\n",
    "                                       norm_layer=norm_layer,   # BN层\n",
    "                                       activation_layer=activation_layer))\n",
    "\n",
    "        # 判断是否需要添加SE模块\n",
    "        if cnf.use_se:\n",
    "            layers.append(SqueezeExcitation(cnf.expanded_c))\n",
    "\n",
    "        # project\n",
    "        layers.append(ConvBNActivation(cnf.expanded_c,\n",
    "                                       cnf.out_c,\n",
    "                                       kernel_size=1,\n",
    "                                       norm_layer=norm_layer,  # BN 层\n",
    "                                       activation_layer=nn.Identity))   # 此层的activation_layer就是进行里普通的线性激活，没有做任何的处理\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.out_channels = cnf.out_c\n",
    "        self.is_strided = cnf.stride > 1\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        result = self.block(x)\n",
    "        if self.use_res_connect:\n",
    "            result += x   # 进行shortcut连接\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "# MobileNetV3网络结构基础框架：其包括：模型的第一层卷积层———>nx【bneckBlock模块】———>1x1的卷积层———>自适应平均池化层———>全连接层———>全连接层\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self,\n",
    "                 inverted_residual_setting: List[InvertedResidualConfig],           # beneckBlock结构一系列参数列表\n",
    "                 last_channel: int,   # 对应的是倒数第二个全连接层输出节点数  1280\n",
    "                 num_classes: int = 1000,  # 类别个数\n",
    "                 block: Optional[Callable[..., nn.Module]] = None,   # InvertedResidual核心模块\n",
    "                 norm_layer: Optional[Callable[..., nn.Module]] = None):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "\n",
    "        if not inverted_residual_setting:\n",
    "            raise ValueError(\"The inverted_residual_setting should not be empty.\")\n",
    "        elif not (isinstance(inverted_residual_setting, List) and\n",
    "                  all([isinstance(s, InvertedResidualConfig) for s in inverted_residual_setting])):\n",
    "            raise TypeError(\"The inverted_residual_setting should be List[InvertedResidualConfig]\")\n",
    "\n",
    "        if block is None:\n",
    "            block = InvertedResidual   # block类\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = partial(nn.BatchNorm2d, eps=0.001, momentum=0.01)  # partial()为python方法，即为nn.BatchNorm2d传入默认的两个参数\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "\n",
    "        # building first layer\n",
    "        # 构建第一层卷积结构\n",
    "        firstconv_output_c = inverted_residual_setting[0].input_c   # 表示第一个卷积层输出的channel数\n",
    "        layers.append(ConvBNActivation(3,   # 输入图像数据的channel数\n",
    "                                       firstconv_output_c,    # 输出channel\n",
    "                                       kernel_size=3,\n",
    "                                       stride=2,\n",
    "                                       norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Hardswish))\n",
    "        # building inverted residual blocks\n",
    "        # 利用循环的方式添加block模块，将每层的配置文件传给block\n",
    "        for cnf in inverted_residual_setting:\n",
    "            layers.append(block(cnf, norm_layer))\n",
    "\n",
    "        # building last several layers\n",
    "        lastconv_input_c = inverted_residual_setting[-1].out_c  # 最后的bneckblock的输出channel\n",
    "        lastconv_output_c = 6 * lastconv_input_c    # lastconv_output_c 与 最后的bneckblock的输出channel数是六倍的关系\n",
    "\n",
    "        # 定义最后一层的卷积层\n",
    "        layers.append(ConvBNActivation(lastconv_input_c,   # 最后的bneckblock的输出channel数\n",
    "                                       lastconv_output_c,   # lastconv_output_c 与 最后的bneckblock的输出channel数是六倍的关系\n",
    "                                       kernel_size=1,\n",
    "                                       norm_layer=norm_layer,\n",
    "                                       activation_layer=nn.Hardswish))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(nn.Linear(lastconv_output_c, last_channel),\n",
    "                                        nn.Hardswish(inplace=True),\n",
    "                                        nn.Dropout(p=0.2, inplace=True),\n",
    "                                        nn.Linear(last_channel, num_classes))\n",
    "\n",
    "        # initial weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "\n",
    "\n",
    "### 构建large基础mobilenet_v3_large模型\n",
    "def mobilenet_v3_large(num_classes: int = 1000,\n",
    "                       reduced_tail: bool = False) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a large MobileNetV3 architecture from\n",
    "    \"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>.\n",
    "\n",
    "    weights_link:\n",
    "    https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes\n",
    "        reduced_tail (bool): If True, reduces the channel counts of all feature layers\n",
    "            between C4 and C5 by 2. It is used to reduce the channel redundancy in the\n",
    "            backbone for Detection and Segmentation.\n",
    "    \"\"\"\n",
    "    width_multi = 1.0\n",
    "    bneck_conf = partial(InvertedResidualConfig, width_multi=width_multi)\n",
    "    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_multi=width_multi)\n",
    "\n",
    "    reduce_divider = 2 if reduced_tail else 1   # 是否较少网络参数标志，默认是False，即不减少\n",
    "\n",
    "    # # beneckBlock结构一系列参数列表\n",
    "    inverted_residual_setting = [\n",
    "        # input_c, kernel, expanded_c, out_c, use_se, activation, stride\n",
    "        bneck_conf(16, 3, 16, 16, False, \"RE\", 1),\n",
    "        bneck_conf(16, 3, 64, 24, False, \"RE\", 2),  # C1\n",
    "        bneck_conf(24, 3, 72, 24, False, \"RE\", 1),\n",
    "        bneck_conf(24, 5, 72, 40, True, \"RE\", 2),  # C2\n",
    "        bneck_conf(40, 5, 120, 40, True, \"RE\", 1),\n",
    "        bneck_conf(40, 5, 120, 40, True, \"RE\", 1),\n",
    "        bneck_conf(40, 3, 240, 80, False, \"HS\", 2),  # C3\n",
    "        bneck_conf(80, 3, 200, 80, False, \"HS\", 1),\n",
    "        bneck_conf(80, 3, 184, 80, False, \"HS\", 1),\n",
    "        bneck_conf(80, 3, 184, 80, False, \"HS\", 1),\n",
    "        bneck_conf(80, 3, 480, 112, True, \"HS\", 1),\n",
    "        bneck_conf(112, 3, 672, 112, True, \"HS\", 1),\n",
    "        bneck_conf(112, 5, 672, 160 // reduce_divider, True, \"HS\", 2),  # C4\n",
    "        bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1),\n",
    "        bneck_conf(160 // reduce_divider, 5, 960 // reduce_divider, 160 // reduce_divider, True, \"HS\", 1),\n",
    "    ]\n",
    "    last_channel = adjust_channels(1280 // reduce_divider)  # C5\n",
    "\n",
    "    return MobileNetV3(inverted_residual_setting=inverted_residual_setting,\n",
    "                       last_channel=last_channel,\n",
    "                       num_classes=num_classes)\n",
    "\n",
    "### 构建small基础mobilenet_v3_small模型\n",
    "def mobilenet_v3_small(num_classes: int = 1000,\n",
    "                       reduced_tail: bool = False) -> MobileNetV3:\n",
    "    \"\"\"\n",
    "    Constructs a large MobileNetV3 architecture from\n",
    "    \"Searching for MobileNetV3\" <https://arxiv.org/abs/1905.02244>.\n",
    "\n",
    "    weights_link:\n",
    "    https://download.pytorch.org/models/mobilenet_v3_small-047dcff4.pth\n",
    "\n",
    "    Args:\n",
    "        num_classes (int): number of classes\n",
    "        reduced_tail (bool): If True, reduces the channel counts of all feature layers\n",
    "            between C4 and C5 by 2. It is used to reduce the channel redundancy in the\n",
    "            backbone for Detection and Segmentation.\n",
    "    \"\"\"\n",
    "    width_multi = 1.0\n",
    "    bneck_conf = partial(InvertedResidualConfig, width_multi=width_multi)\n",
    "    adjust_channels = partial(InvertedResidualConfig.adjust_channels, width_multi=width_multi)\n",
    "\n",
    "    reduce_divider = 2 if reduced_tail else 1\n",
    "\n",
    "    inverted_residual_setting = [\n",
    "        # input_c, kernel, expanded_c, out_c, use_se, activation, stride\n",
    "        bneck_conf(16, 3, 16, 16, True, \"RE\", 2),  # C1\n",
    "        bneck_conf(16, 3, 72, 24, False, \"RE\", 2),  # C2\n",
    "        bneck_conf(24, 3, 88, 24, False, \"RE\", 1),\n",
    "        bneck_conf(24, 5, 96, 40, True, \"HS\", 2),  # C3\n",
    "        bneck_conf(40, 5, 240, 40, True, \"HS\", 1),\n",
    "        bneck_conf(40, 5, 240, 40, True, \"HS\", 1),\n",
    "        bneck_conf(40, 5, 120, 48, True, \"HS\", 1),\n",
    "        bneck_conf(48, 5, 144, 48, True, \"HS\", 1),\n",
    "        bneck_conf(48, 5, 288, 96 // reduce_divider, True, \"HS\", 2),  # C4\n",
    "        bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1),\n",
    "        bneck_conf(96 // reduce_divider, 5, 576 // reduce_divider, 96 // reduce_divider, True, \"HS\", 1)\n",
    "    ]\n",
    "    last_channel = adjust_channels(1024 // reduce_divider)  # C5\n",
    "\n",
    "    return MobileNetV3(inverted_residual_setting=inverted_residual_setting,\n",
    "                       last_channel=last_channel,\n",
    "                       num_classes=num_classes)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
